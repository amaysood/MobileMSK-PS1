fasten(EMR):- Open the Github repo and then fork and clone it.Scrolling through the repo we see that fasten is an open-source, self-hosted, personal/family electronic medical record aggregator, designed to integrate with 1000's of insurances/hospitals/clinics.  Basically what fasten does it collects all your medical data possesed by a variety of medical contractors,labs etc and provides it at a single place on a website that is locally hosted on your device. This ensures privacy and tackles one of the biggest issues with EMR’s which is that if you use a third party site to access your medical records it is prone to attacks and invasion of privacy.Another USP of fasten is that it is designed for families unlinke many other popular EMR systems like OpenEMR which are designed for clinics.Diving into the code we see that fasten makes use of docker for api deployement and the primary language is go.In the backend folder we have fasten.go which sets up the server through the main() function and then the logger function helps keep track of all the logs and creates the logfile where they are stored. Moving on pkg contains different packages for different utilities,for example the auth package contains the user authorization part of the backend.jwt_utils makes use of json web tokens to create user key in the form of a web token and has a fucntion to validate the users token aswell checking things like whether the token can be parsed or not,whether the userclaims are correct or not and further checks whether the token has expired or not.We also have user metadata in addition to the user claims which is basically Name,picture and email.Moving on we have the config file and then where the magic happens which is the database package.In this we have the use of gorm to interact with sqlite databases through go.We have various methods in this to interact with the databases,GetUserByUsername,GetSources,ListResources being some examples that communicate with the sqlite databases using sql queries.We also have functionality to plot graaphs of the data once acquired which are displayed on the web app in forms of histograms pie charts etc.Moving on we have errors which has templates for some basic errors like ConfigFileMissing and ConfigValidationError.Models provide us with functionality for defining behaviour of data entities such as data represntation and Database mapping.Utils contain functions to sort the resources according to parameters like Title Date etc.We also have a folder for frontend that uses nodejs and other frameworks and languages to build the visual part of the webapp.To open the web app we need to install docker, and then run two commands.The important information missing in the instructions to run the app is that these command must be run as super user as otherwise “The docker user group exists but contains no users” and hence the we are unable to run the app.After starting the server the we have to go to the local address on browser and we see a login screen.It has functionality for logging in and creating a new account.Once you have made an account and logged in you see a template for how the site would look with your data however the site is not fully funtional right now so you can only see an example of what it would look like.There are options to connect to sources to add EMR data from.All in all fasten is a good tool to accumulate and visualisize EMR data on a local host,but it is still in development and a lot of the features dont work yet.




Yoga pose prediction:- This repo is made to classify live video into one of 7 different yoga poses with the help of PoseNet,ml5js and KNN classifier model.PoseNet is a CNN that helps identify the various joints and the connection between those joints(skeleton).The K-Nearest-Neighbours classifier helps to then classify these poses into one of the seven yoga poses possible in this repo.Lets fork the repo and then clone into it.Starting off with the code.We have data preperation which contains two pieces of code resize and video.resize makes use of the opencv library to make all of the images in the data of the same size.This is to ensure ease for PoseNet after making a video from all these images.The video code again makes use of the opencv library to make a video out of all the images of same size with each image as a frame.As a note both of these codes are not useful for us since these have been just used by the creator of the repo to prepare their data.both of the codes have if name=”main” where the functions have been called to prepare the data.Next we have the static folder which contains all the audio and image files used in the websites.We have p5 which is a library in js for animations graphics etc. The train folder contains the code to train the KNN classifier which also has the utility for training the model through a UI which we can see when we open the train website,it also contains the video with all the images in it.The test folder contains the prediction code as well as a json file of the trained model.In input for the classifier two functions are used namely drawKeypoints() and drawSkeletons() which basically identify the joints and the skeletal structure of the person and shows it as ellipses on joints and lines on the skeletal structure over your webcam.The KNN classifier then predicts confidence levels for each of the seven poses and labels the result as the pose with the highest confidence.The creator of the repo claims that the trained model has an accuracy of 75%. Moving on we have templates for both websites,training and prediction and then we have code for the websites themselves which uses django.There is an issue with the requirements.txt file of this repo as it contains the dependancies with pip install written in front of them so running pip install -r requirements.txt doesnt work.This is an easy fix by just writing the dependancies in requirements.txt.To run the app we first install all the required dependancies then we run the server through manage.py and then we go to the local address where the website is hosted.We can train the model on the train website using buttons to feed examples of different poses to the model,when you are done you receive a json file with the trained model as a download.Now if we go to the predict website we are prompted to give access to our webcam and then we can see PoseNet identifying joints and skeleton on the webcam and the model makes predictions of what pose you are doing from live webcam feed.Overall yoga-pose-detector is a good idea and works pretty well for predicting poses from live video, harnessing the power of PoseNet in the process,however there is no frontend or backend on the websites and also has a quite a bit of redundancies in the code and difficult to follow the instructions in the ReadMe.






Sensormotion(Gait):-Sensormotion is a package that analyzes data accumulated from sensors such as those present in a smartwatch.The package mostly makes use of python.It mainly has two major functionalities i.e analyzing gait dynamics and physical activity counts.The repo also contains a jupyter notebook which is a very convenient example of how the repo works.As usual we fork the repo and then clone it.Starting with the code we have just the one sensormotion package which is of use to us.Looking at the code for gait we see a function for cadence which is basically the number of steps per minute.This function makes use of the find_peaks function with which we shall explore peak.py.It has two functions find_peaks and indexes.indexes first fills out the places where there is plateau in the signal with values from left and right so that the difference isnt 0.It Identifies peaks where the difference goes from negative to positive.It also makes sure that there is only one peak in the specified minimum distance between two peaks by taking the highest peak amongst the multiple peaks.find_peaks first detrends the signal based on whether the user has asked it to or not,it then uses indexes to find peaks or valleys or both based on the specification.After that we have functionality to plot the signals.Coming back to gait cadence now use find_peaks through stepcounts() which is basically number of steps is equal to the number of peaks in the signal.With the number of steps cadence is easily calculated as steps/min.We have step_regularity which calculates the autocorrelation(comparison of a signal with a delayed version of itself) of the peaks in the second half and calculates the ratio of autocorrelation of  oringal(lag0) with the lag1(one step[left-right]) autocorrelation and the same with lag2(one-stride[left-left]) hence finding the step and the stride regularity.It is worthy to not that the values of autocorrelations varies from -1 to 1.Similarly we have step symmetry which calculates the symmetry of the steps by taking ratio of the autocorrelation of the first and second dominant period(lag1 and lag2).step_time just give us the mean,sd and coefficient of variation of the time taken for steps.plot.py just has two funtions to plot the filter response of a signal and the signal itself.Next we have the signal folder,which I found to be the most exciting because it took practical examples of signal processing used in sensor.In signal.py we have the baseline function which fits a polynomial to the signal to figure out if there exists a trend in the signal or not.Build_filter builds a butterworth filter using Nyquist criterion,which uses the nyquist rate i.e. half of the sample rate.If it is a bandpass filter two cutoff frequencies are present between which all frequencies are passed else only one frequency is the cutoff frequency below which all frequencies are passed by the filter.Then we have detrend signal which removes the trend from a signal by subtracting the baseline from the signal.We have fft(Fast Fourier Transform) which is an algortihm to quickly calculate the Fourier Transform of a Signals which gives us the dominant frequencies present in the signal in a frequency response.We also have vector_magnitude which in the case of a triaxial sensore(three coordinates) calculates the euclidean norm of the coordinates which can be further used.Finally we get to the second major application of the sensormotion package that is Physical Activity.convertcounts() converts the acceleration signal to PA counts which is the area under the acceleration signal at different epochs(time frames).Epochs are generally taken to be 60s in the classification used by the reasearch paper in the code.The function plots the PA counts across different epochs in the form of a bar chart.Cutpoints() just has the different cuttoffs for various types of people like children,women,adults etc. Used to classify PA counts into different categories on the basis of intensity of the excersize.The function outputs lines on the same chart as the one with bars of the PA counts and then prints a list which contains the intensity of each of the epochs.tutorial is a jupyter notebook included in the repo that gives an example of how all the funcitons work and helps visualize the functions outputs through graphs.All in all sensormotion has well commented and easy to read code,it is also easy to run I had the least difficulty in understanding the repo,however its functionality is very limited as it does not have an ML model its basically just a signal processing tool,its good for getting metrics from the signal but doesnt take any inferences from the metrics it provides.
